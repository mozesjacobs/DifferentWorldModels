{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mdn-rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdtQlZL1RcTL"
      },
      "source": [
        "#Code to get MDN-RNN Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-amxgynvRPu",
        "outputId": "cdb40375-2959-45dc-8b96-36349f92911a"
      },
      "source": [
        "import torch\n",
        "print('Version', torch.__version__)\n",
        "print('CUDA enabled:', torch.cuda.is_available())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version 1.7.0+cu101\n",
            "CUDA enabled: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvaGchoeyNKu",
        "outputId": "32454bab-9dc6-4e77-c00d-61dced7c5b4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2-hbkrZyKHX"
      },
      "source": [
        "import os\n",
        "BASE_PATH = '/gdrive/My Drive/colab_files/Final Project/'\n",
        "os.chdir(BASE_PATH)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gsq2EsVzUGs"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftbmdy8rvl4-"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as f\n",
        "from torch.distributions.normal import Normal"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knLYNW0TyZNb",
        "outputId": "41a8603a-1c1f-48c5-8f20-69f5f027f16f"
      },
      "source": [
        "USE_CUDA = True\n",
        "use_cuda = USE_CUDA and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print('Using device', device)\n",
        "import multiprocessing\n",
        "NUM_WORKERS = multiprocessing.cpu_count()\n",
        "print('num workers:', NUM_WORKERS)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device cuda\n",
            "num workers: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_6evo8urppI"
      },
      "source": [
        "\"\"\" Learning utilities \"\"\"\n",
        "from functools import partial\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "class EarlyStopping(object): # pylint: disable=R0902\n",
        "    \"\"\"\n",
        "    Gives a criterion to stop training when a given metric is not\n",
        "    improving anymore\n",
        "    Args:\n",
        "        mode (str): One of `min`, `max`. In `min` mode, training will\n",
        "            be stopped when the quantity monitored has stopped\n",
        "            decreasing; in `max` mode it will be stopped when the\n",
        "            quantity monitored has stopped increasing. Default: 'min'.\n",
        "        patience (int): Number of epochs with no improvement after\n",
        "            which training is stopped. For example, if\n",
        "            `patience = 2`, then we will ignore the first 2 epochs\n",
        "            with no improvement, and will only stop learning after the\n",
        "            3rd epoch if the loss still hasn't improved then.\n",
        "            Default: 10.\n",
        "        threshold (float): Threshold for measuring the new optimum,\n",
        "            to only focus on significant changes. Default: 1e-4.\n",
        "        threshold_mode (str): One of `rel`, `abs`. In `rel` mode,\n",
        "            dynamic_threshold = best * ( 1 + threshold ) in 'max'\n",
        "            mode or best * ( 1 - threshold ) in `min` mode.\n",
        "            In `abs` mode, dynamic_threshold = best + threshold in\n",
        "            `max` mode or best - threshold in `min` mode. Default: 'rel'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mode='min', patience=10, threshold=1e-4, threshold_mode='rel'):\n",
        "        self.patience = patience\n",
        "        self.mode = mode\n",
        "        self.threshold = threshold\n",
        "        self.threshold_mode = threshold_mode\n",
        "        self.best = None\n",
        "        self.num_bad_epochs = None\n",
        "        self.mode_worse = None  # the worse value for the chosen mode\n",
        "        self.is_better = None\n",
        "        self.last_epoch = -1\n",
        "        self._init_is_better(mode=mode, threshold=threshold,\n",
        "                             threshold_mode=threshold_mode)\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self):\n",
        "        \"\"\"Resets num_bad_epochs counter and cooldown counter.\"\"\"\n",
        "        self.best = self.mode_worse\n",
        "        self.num_bad_epochs = 0\n",
        "\n",
        "    def step(self, metrics, epoch=None):\n",
        "        \"\"\" Updates early stopping state \"\"\"\n",
        "        current = metrics\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch = self.last_epoch + 1\n",
        "        self.last_epoch = epoch\n",
        "\n",
        "        if self.is_better(current, self.best):\n",
        "            self.best = current\n",
        "            self.num_bad_epochs = 0\n",
        "        else:\n",
        "            self.num_bad_epochs += 1\n",
        "\n",
        "    @property\n",
        "    def stop(self):\n",
        "        \"\"\" Should we stop learning? \"\"\"\n",
        "        return self.num_bad_epochs > self.patience\n",
        "\n",
        "\n",
        "    def _cmp(self, mode, threshold_mode, threshold, a, best): # pylint: disable=R0913, R0201\n",
        "        if mode == 'min' and threshold_mode == 'rel':\n",
        "            rel_epsilon = 1. - threshold\n",
        "            return a < best * rel_epsilon\n",
        "\n",
        "        elif mode == 'min' and threshold_mode == 'abs':\n",
        "            return a < best - threshold\n",
        "\n",
        "        elif mode == 'max' and threshold_mode == 'rel':\n",
        "            rel_epsilon = threshold + 1.\n",
        "            return a > best * rel_epsilon\n",
        "\n",
        "        return a > best + threshold\n",
        "\n",
        "    def _init_is_better(self, mode, threshold, threshold_mode):\n",
        "        if mode not in {'min', 'max'}:\n",
        "            raise ValueError('mode ' + mode + ' is unknown!')\n",
        "        if threshold_mode not in {'rel', 'abs'}:\n",
        "            raise ValueError('threshold mode ' + threshold_mode + ' is unknown!')\n",
        "\n",
        "        if mode == 'min':\n",
        "            self.mode_worse = float('inf')\n",
        "        else:  # mode == 'max':\n",
        "            self.mode_worse = (-float('inf'))\n",
        "\n",
        "        self.is_better = partial(self._cmp, mode, threshold_mode, threshold)\n",
        "\n",
        "    def state_dict(self):\n",
        "        \"\"\" Returns early stopping state \"\"\"\n",
        "        return {key: value for key, value in self.__dict__.items() if key != 'is_better'}\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        \"\"\" Loads early stopping state \"\"\"\n",
        "        self.__dict__.update(state_dict)\n",
        "        self._init_is_better(mode=self.mode, threshold=self.threshold,\n",
        "                             threshold_mode=self.threshold_mode)\n",
        "\n",
        "\n",
        "\n",
        "############################################################\n",
        "#### WARNING : THIS IS A TEMPORARY CODE WHICH HAS      #####\n",
        "####  TO BE REMOVED WITH PYTORCH 0.5                   #####\n",
        "#### IT IS COPY OF THE 0.5 VERSION OF THE LR SCHEDULER #####\n",
        "############################################################\n",
        "class ReduceLROnPlateau(object): # pylint: disable=R0902\n",
        "    \"\"\"Reduce learning rate when a metric has stopped improving.\n",
        "    Models often benefit from reducing the learning rate by a factor\n",
        "    of 2-10 once learning stagnates. This scheduler reads a metrics\n",
        "    quantity and if no improvement is seen for a 'patience' number\n",
        "    of epochs, the learning rate is reduced.\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        mode (str): One of `min`, `max`. In `min` mode, lr will\n",
        "            be reduced when the quantity monitored has stopped\n",
        "            decreasing; in `max` mode it will be reduced when the\n",
        "            quantity monitored has stopped increasing. Default: 'min'.\n",
        "        factor (float): Factor by which the learning rate will be\n",
        "            reduced. new_lr = lr * factor. Default: 0.1.\n",
        "        patience (int): Number of epochs with no improvement after\n",
        "            which learning rate will be reduced. For example, if\n",
        "            `patience = 2`, then we will ignore the first 2 epochs\n",
        "            with no improvement, and will only decrease the LR after the\n",
        "            3rd epoch if the loss still hasn't improved then.\n",
        "            Default: 10.\n",
        "        verbose (bool): If ``True``, prints a message to stdout for\n",
        "            each update. Default: ``False``.\n",
        "        threshold (float): Threshold for measuring the new optimum,\n",
        "            to only focus on significant changes. Default: 1e-4.\n",
        "        threshold_mode (str): One of `rel`, `abs`. In `rel` mode,\n",
        "            dynamic_threshold = best * ( 1 + threshold ) in 'max'\n",
        "            mode or best * ( 1 - threshold ) in `min` mode.\n",
        "            In `abs` mode, dynamic_threshold = best + threshold in\n",
        "            `max` mode or best - threshold in `min` mode. Default: 'rel'.\n",
        "        cooldown (int): Number of epochs to wait before resuming\n",
        "            normal operation after lr has been reduced. Default: 0.\n",
        "        min_lr (float or list): A scalar or a list of scalars. A\n",
        "            lower bound on the learning rate of all param groups\n",
        "            or each group respectively. Default: 0.\n",
        "        eps (float): Minimal decay applied to lr. If the difference\n",
        "            between new and old lr is smaller than eps, the update is\n",
        "            ignored. Default: 1e-8.\n",
        "    Example:\n",
        "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "        >>> scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
        "        >>> for epoch in range(10):\n",
        "        >>>     train(...)\n",
        "        >>>     val_loss = validate(...)\n",
        "        >>>     # Note that step should be called after validate()\n",
        "        >>>     scheduler.step(val_loss)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, mode='min', factor=0.1, patience=10, # pylint: disable=R0913\n",
        "                 verbose=False, threshold=1e-4, threshold_mode='rel',\n",
        "                 cooldown=0, min_lr=0, eps=1e-8):\n",
        "\n",
        "        if factor >= 1.0:\n",
        "            raise ValueError('Factor should be < 1.0.')\n",
        "        self.factor = factor\n",
        "\n",
        "        if not isinstance(optimizer, Optimizer):\n",
        "            raise TypeError('{} is not an Optimizer'.format(\n",
        "                type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        if isinstance(min_lr, (list, tuple)):\n",
        "            if len(min_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} min_lrs, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(min_lr)))\n",
        "            self.min_lrs = list(min_lr)\n",
        "        else:\n",
        "            self.min_lrs = [min_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.cooldown = cooldown\n",
        "        self.cooldown_counter = 0\n",
        "        self.mode = mode\n",
        "        self.threshold = threshold\n",
        "        self.threshold_mode = threshold_mode\n",
        "        self.best = None\n",
        "        self.num_bad_epochs = None\n",
        "        self.mode_worse = None  # the worse value for the chosen mode\n",
        "        self.is_better = None\n",
        "        self.eps = eps\n",
        "        self.last_epoch = -1\n",
        "        self._init_is_better(mode=mode, threshold=threshold,\n",
        "                             threshold_mode=threshold_mode)\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self):\n",
        "        \"\"\"Resets num_bad_epochs counter and cooldown counter.\"\"\"\n",
        "        self.best = self.mode_worse\n",
        "        self.cooldown_counter = 0\n",
        "        self.num_bad_epochs = 0\n",
        "\n",
        "    def step(self, metrics, epoch=None):\n",
        "        \"\"\" Updates scheduler state \"\"\"\n",
        "        current = metrics\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch = self.last_epoch + 1\n",
        "        self.last_epoch = epoch\n",
        "\n",
        "        if self.is_better(current, self.best):\n",
        "            self.best = current\n",
        "            self.num_bad_epochs = 0\n",
        "        else:\n",
        "            self.num_bad_epochs += 1\n",
        "\n",
        "        if self.in_cooldown:\n",
        "            self.cooldown_counter -= 1\n",
        "            self.num_bad_epochs = 0  # ignore any bad epochs in cooldown\n",
        "\n",
        "        if self.num_bad_epochs > self.patience:\n",
        "            self._reduce_lr(epoch)\n",
        "            self.cooldown_counter = self.cooldown\n",
        "            self.num_bad_epochs = 0\n",
        "\n",
        "    def _reduce_lr(self, epoch):\n",
        "        for i, param_group in enumerate(self.optimizer.param_groups):\n",
        "            old_lr = float(param_group['lr'])\n",
        "            new_lr = max(old_lr * self.factor, self.min_lrs[i])\n",
        "            if old_lr - new_lr > self.eps:\n",
        "                param_group['lr'] = new_lr\n",
        "                if self.verbose:\n",
        "                    print('Epoch {:5d}: reducing learning rate'\n",
        "                          ' of group {} to {:.4e}.'.format(epoch, i, new_lr))\n",
        "\n",
        "    @property\n",
        "    def in_cooldown(self):\n",
        "        \"\"\" Are we on CD? \"\"\"\n",
        "        return self.cooldown_counter > 0\n",
        "\n",
        "    def _cmp(self, mode, threshold_mode, threshold, a, best): # pylint: disable=R0913,R0201\n",
        "        if mode == 'min' and threshold_mode == 'rel':\n",
        "            rel_epsilon = 1. - threshold\n",
        "            return a < best * rel_epsilon\n",
        "\n",
        "        elif mode == 'min' and threshold_mode == 'abs':\n",
        "            return a < best - threshold\n",
        "\n",
        "        elif mode == 'max' and threshold_mode == 'rel':\n",
        "            rel_epsilon = threshold + 1.\n",
        "            return a > best * rel_epsilon\n",
        "\n",
        "        return a > best + threshold\n",
        "\n",
        "    def _init_is_better(self, mode, threshold, threshold_mode):\n",
        "        if mode not in {'min', 'max'}:\n",
        "            raise ValueError('mode ' + mode + ' is unknown!')\n",
        "        if threshold_mode not in {'rel', 'abs'}:\n",
        "            raise ValueError('threshold mode ' + threshold_mode + ' is unknown!')\n",
        "\n",
        "        if mode == 'min':\n",
        "            self.mode_worse = float('inf')\n",
        "        else:  # mode == 'max':\n",
        "            self.mode_worse = (-float('inf'))\n",
        "\n",
        "        self.is_better = partial(self._cmp, mode, threshold_mode, threshold)\n",
        "\n",
        "    def state_dict(self):\n",
        "        \"\"\" Returns scheduler state \"\"\"\n",
        "        return {key: value for key, value in self.__dict__.items()\n",
        "                if key not in {'optimizer', 'is_better'}}\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        \"\"\" Loads scheduler state \"\"\"\n",
        "        self.__dict__.update(state_dict)\n",
        "        self._init_is_better(mode=self.mode, threshold=self.threshold,\n",
        "                             threshold_mode=self.threshold_mode)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcrJa9SsvpL6"
      },
      "source": [
        "def gmm_loss(batch, mus, sigmas, logpi, reduce=True): # pylint: disable=too-many-arguments\n",
        "    \"\"\" Computes the Gaussian Mixture Model (GMM) loss.\n",
        "    Compute minus the log probability of batch under the GMM model described\n",
        "    by mus, sigmas, pi. Precisely, with bs1, bs2, ... the sizes of the batch\n",
        "    dimensions (several batch dimension are useful when you have both a batch\n",
        "    axis and a time step axis), gs the number of mixtures and fs the number of\n",
        "    features.\n",
        "    :args batch: (bs1, bs2, *, fs) torch tensor\n",
        "    :args mus: (bs1, bs2, *, gs, fs) torch tensor\n",
        "    :args sigmas: (bs1, bs2, *, gs, fs) torch tensor\n",
        "    :args logpi: (bs1, bs2, *, gs) torch tensor\n",
        "    :args reduce: if not reduce, the mean in the following formula is ommited\n",
        "    :returns:\n",
        "    loss(batch) = - mean_{i1=0..bs1, i2=0..bs2, ...} log(\n",
        "        sum_{k=1..gs} pi[i1, i2, ..., k] * N(\n",
        "            batch[i1, i2, ..., :] | mus[i1, i2, ..., k, :], sigmas[i1, i2, ..., k, :]))\n",
        "    NOTE: The loss is not reduced along the feature dimension (i.e. it should scale ~linearily\n",
        "    with fs).\n",
        "    \"\"\"\n",
        "    batch = batch.unsqueeze(-2)\n",
        "    normal_dist = Normal(mus, sigmas)\n",
        "    g_log_probs = normal_dist.log_prob(batch)\n",
        "    g_log_probs = logpi + torch.sum(g_log_probs, dim=-1)\n",
        "    max_log_probs = torch.max(g_log_probs, dim=-1, keepdim=True)[0]\n",
        "    g_log_probs = g_log_probs - max_log_probs\n",
        "\n",
        "    g_probs = torch.exp(g_log_probs)\n",
        "    probs = torch.sum(g_probs, dim=-1)\n",
        "\n",
        "    log_prob = max_log_probs.squeeze() + torch.log(probs)\n",
        "    if reduce:\n",
        "        return - torch.mean(log_prob)\n",
        "    return - torch.sum(log_prob)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ6hVX3U6Lio"
      },
      "source": [
        "def get_loss(latent_obs, action, reward, terminal,\n",
        "             latent_next_obs, mdrnn, include_reward: bool):\n",
        "    \"\"\" Compute losses.\n",
        "    The loss that is computed is:\n",
        "    (GMMLoss(latent_next_obs, GMMPredicted) + MSE(reward, predicted_reward) +\n",
        "         BCE(terminal, logit_terminal)) / (LSIZE + 2)\n",
        "    The LSIZE + 2 factor is here to counteract the fact that the GMMLoss scales\n",
        "    approximately linearily with LSIZE. All losses are averaged both on the\n",
        "    batch and the sequence dimensions (the two first dimensions).\n",
        "    :args latent_obs: (BSIZE, SEQ_LEN, LSIZE) torch tensor\n",
        "    :args action: (BSIZE, SEQ_LEN, ASIZE) torch tensor\n",
        "    :args reward: (BSIZE, SEQ_LEN) torch tensor\n",
        "    :args latent_next_obs: (BSIZE, SEQ_LEN, LSIZE) torch tensor\n",
        "    :returns: dictionary of losses, containing the gmm, the mse, the bce and\n",
        "        the averaged loss.\n",
        "    \"\"\"\n",
        "    latent_obs, action,\\\n",
        "        reward, terminal,\\\n",
        "        latent_next_obs = [arr.transpose(1, 0)\n",
        "                           for arr in [latent_obs, action,\n",
        "                                       reward, terminal,\n",
        "                                       latent_next_obs]]\n",
        "    mus, sigmas, logpi, rs, ds = mdrnn(action, latent_obs)\n",
        "    gmm = gmm_loss(latent_next_obs, mus, sigmas, logpi)\n",
        "    bce = f.binary_cross_entropy_with_logits(ds, terminal)\n",
        "    if include_reward:\n",
        "        mse = f.mse_loss(rs, reward)\n",
        "        scale = LATENT_SIZE + 2\n",
        "    else:\n",
        "        mse = 0\n",
        "        scale = LATENT_SIZE + 1\n",
        "    loss = (gmm + bce + mse) / scale\n",
        "    return dict(gmm=gmm, bce=bce, mse=mse, loss=loss)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN_qW6zXv1zL"
      },
      "source": [
        "class _MDRNNBase(nn.Module):\n",
        "    def __init__(self, latents, actions, hiddens, gaussians):\n",
        "        super(_MDRNNBase, self).__init__()\n",
        "        self.latents = latents\n",
        "        self.actions = actions\n",
        "        self.hiddens = hiddens\n",
        "        self.gaussians = gaussians\n",
        "\n",
        "        self.gmm_linear = nn.Linear(\n",
        "            hiddens, (2 * latents + 1) * gaussians + 2)\n",
        "\n",
        "    def forward(self, *inputs):\n",
        "        pass"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd8Q8fDRtgyf"
      },
      "source": [
        "class MDRNN(_MDRNNBase):\n",
        "    \"\"\" MDRNN model for multi steps forward \"\"\"\n",
        "    def __init__(self, latents, actions, hiddens, gaussians):\n",
        "        super(MDRNN, self).__init__(latents, actions, hiddens, gaussians)\n",
        "        self.rnn = nn.LSTM(latents + actions, hiddens)\n",
        "\n",
        "    def forward(self, actions, latents): # pylint: disable=arguments-differ\n",
        "        \"\"\" MULTI STEPS forward.\n",
        "        :args actions: (SEQ_LEN, BSIZE, ASIZE) torch tensor\n",
        "        :args latents: (SEQ_LEN, BSIZE, LSIZE) torch tensor\n",
        "        :returns: mu_nlat, sig_nlat, pi_nlat, rs, ds, parameters of the GMM\n",
        "        prediction for the next latent -> rs, gaussian prediction of the reward and\n",
        "        logit prediction of terminality -> ds.\n",
        "            - mu_nlat: (SEQ_LEN, BSIZE, N_GAUSS, LSIZE) torch tensor\n",
        "            - sigma_nlat: (SEQ_LEN, BSIZE, N_GAUSS, LSIZE) torch tensor\n",
        "            - logpi_nlat: (SEQ_LEN, BSIZE, N_GAUSS) torch tensor\n",
        "            - rs: (SEQ_LEN, BSIZE) torch tensor\n",
        "            - ds: (SEQ_LEN, BSIZE) torch tensor\n",
        "        \"\"\"\n",
        "        seq_len, bs = actions.size(0), actions.size(1)\n",
        "\n",
        "        ins = torch.cat([actions, latents], dim=-1)\n",
        "        outs, _ = self.rnn(ins)\n",
        "        gmm_outs = self.gmm_linear(outs)\n",
        "\n",
        "        stride = self.gaussians * self.latents\n",
        "\n",
        "        mus = gmm_outs[:, :, :stride]\n",
        "        mus = mus.view(seq_len, bs, self.gaussians, self.latents)\n",
        "\n",
        "        sigmas = gmm_outs[:, :, stride:2 * stride]\n",
        "        sigmas = sigmas.view(seq_len, bs, self.gaussians, self.latents)\n",
        "        sigmas = torch.exp(sigmas)\n",
        "\n",
        "        pi = gmm_outs[:, :, 2 * stride: 2 * stride + self.gaussians]\n",
        "        pi = pi.view(seq_len, bs, self.gaussians)\n",
        "        logpi = f.log_softmax(pi, dim=-1)\n",
        "\n",
        "        rs = gmm_outs[:, :, -2]\n",
        "\n",
        "        ds = gmm_outs[:, :, -1]\n",
        "\n",
        "        return mus, sigmas, logpi, rs, ds"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "370wXnXMutwe"
      },
      "source": [
        "class MDRNNCell(_MDRNNBase):\n",
        "    \"\"\" MDRNN model for one step forward \"\"\"\n",
        "    def __init__(self, latents, actions, hiddens, gaussians):\n",
        "        super(MDRNNCell, self).__init__(latents, actions, hiddens, gaussians)\n",
        "        self.rnn = nn.LSTMCell(latents + actions, hiddens)\n",
        "\n",
        "    def forward(self, action, latent, hidden): # pylint: disable=arguments-differ\n",
        "        \"\"\" ONE STEP forward.\n",
        "        :args actions: (BSIZE, ASIZE) torch tensor\n",
        "        :args latents: (BSIZE, LSIZE) torch tensor\n",
        "        :args hidden: (BSIZE, RSIZE) torch tensor\n",
        "        :returns: mu_nlat, sig_nlat, pi_nlat, r, d, next_hidden, parameters of\n",
        "        the GMM prediction for the next latent, gaussian prediction of the\n",
        "        reward, logit prediction of terminality and next hidden state.\n",
        "            - mu_nlat: (BSIZE, N_GAUSS, LSIZE) torch tensor\n",
        "            - sigma_nlat: (BSIZE, N_GAUSS, LSIZE) torch tensor\n",
        "            - logpi_nlat: (BSIZE, N_GAUSS) torch tensor\n",
        "            - rs: (BSIZE) torch tensor\n",
        "            - ds: (BSIZE) torch tensor\n",
        "        \"\"\"\n",
        "        in_al = torch.cat([action, latent], dim=1)\n",
        "\n",
        "        next_hidden = self.rnn(in_al, hidden)\n",
        "        out_rnn = next_hidden[0]\n",
        "\n",
        "        out_full = self.gmm_linear(out_rnn)\n",
        "\n",
        "        stride = self.gaussians * self.latents\n",
        "\n",
        "        mus = out_full[:, :stride]\n",
        "        mus = mus.view(-1, self.gaussians, self.latents)\n",
        "\n",
        "        sigmas = out_full[:, stride:2 * stride]\n",
        "        sigmas = sigmas.view(-1, self.gaussians, self.latents)\n",
        "        sigmas = torch.exp(sigmas)\n",
        "\n",
        "        pi = out_full[:, 2 * stride:2 * stride + self.gaussians]\n",
        "        pi = pi.view(-1, self.gaussians)\n",
        "        logpi = f.log_softmax(pi, dim=-1)\n",
        "\n",
        "        r = out_full[:, -2]\n",
        "\n",
        "        d = out_full[:, -1]\n",
        "\n",
        "        return mus, sigmas, logpi, r, d, next_hidden"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOhe2zr6xm1b"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, device, batch_size=250):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, stride=2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.mufc = nn.Linear(1024, 32)\n",
        "        self.logvarfc = nn.Linear(1024, 32)\n",
        "        \n",
        "        self.decoder_fc = nn.Linear(32, 1024)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(1024, 128, 5, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 5, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 6, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, 6, stride=2),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        #self.dist = torch.distributions.laplace.Laplace(0, torch.ones([50]))\n",
        "        \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        #noise = torch.randn(self.batch_size, 32).to(self.device)\n",
        "        noise = torch.randn_like(std).to(self.device)\n",
        "        return mu + std * noise # z\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.reshape(-1, 1024)\n",
        "        mu, logvar = self.mufc(x), self.logvarfc(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        z_ = self.decoder_fc(z)\n",
        "        z_ = z_.reshape(-1, 1024, 1, 1)\n",
        "        return self.decoder(z_.float()), mu, logvar\n",
        "    \n",
        "    def get_z(self, x):\n",
        "        with torch.no_grad():\n",
        "            encoded = self.encoder(x).reshape(-1, 1024)\n",
        "            mu, logvar = self.mufc(encoded), self.logvarfc(encoded)\n",
        "            return self.reparameterize(mu, logvar)\n",
        "\n",
        "    def get_reconstruction(self, mu, logvar):\n",
        "      z = self.reparameterize(mu, logvar)\n",
        "      z_ = self.decoder_fc(z)\n",
        "      z_ = z_.reshape(-1, 1024, 1, 1)\n",
        "      return self.decoder(z_.float())\n",
        "\n",
        "    def get_recon(self, latent_obs):\n",
        "      z = self.decoder_fc(latent_obs)\n",
        "      z = z.reshape(-1, 1024, 1, 1)\n",
        "      return self.decoder(z.float())\n",
        "\n",
        "    def loss_func(self, x, x_prime, mu, logvar):\n",
        "      recon_loss = nn.BCELoss(reduction='sum')\n",
        "      loss = recon_loss(x_prime, x)\n",
        "      loss += -0.5 * torch.sum(1 + logvar - mu.pow(2) - torch.exp(logvar))\n",
        "\n",
        "      return loss"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crw7-gOEx9rn",
        "outputId": "438bd4c7-57d7-4db8-9d46-6cee9daff1df"
      },
      "source": [
        "vae = VAE(device)\n",
        "vae.to(device, dtype=torch.float)\n",
        "vae_path = BASE_PATH + \"weights/vae_nonorm_b1.pt\"\n",
        "vae.load_state_dict(torch.load(vae_path))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRsFQygUyWrG"
      },
      "source": [
        "class RolloutVaeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dir_path, transform=None):\n",
        "        super(RolloutVaeDataset, self).__init__()\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        self.data = []\n",
        "        if (dir_path[-1] != '/'):\n",
        "            dir_path += '/'\n",
        "        for file in os.listdir(dir_path):\n",
        "          file_np = np.load(dir_path + str(file))\n",
        "          imgs = file_np['obs'] # 1000 x 64 x 64 x 3\n",
        "          actions = file_np['action']\n",
        "          for i in range(len(imgs)):\n",
        "            curr_img = imgs[i]\n",
        "            curr_action = actions[i]\n",
        "            self.data.append((curr_img, curr_action))\n",
        "            #self.data.append((np.transpose(curr_img, (2, 0, 1))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        # TODO\n",
        "        if (self.transform):\n",
        "          return self.transform(self.data[idx][0]), torch.tensor(self.data[idx][1])\n",
        "        else:\n",
        "          return torch.tensor(self.data[idx][0]), torch.tensor(self.data[idx][1])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3aLa8n5jPgs"
      },
      "source": [
        "\"\"\" Some data loading utilities \"\"\"\n",
        "from bisect import bisect\n",
        "from os import listdir\n",
        "from os.path import join, isdir\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "\n",
        "class _RolloutDataset(torch.utils.data.Dataset): # pylint: disable=too-few-public-methods\n",
        "    def __init__(self, root, transform, buffer_size=200, train=True): # pylint: disable=too-many-arguments\n",
        "        self._transform = transform\n",
        "\n",
        "        self._files = [root + \"/\" + file for file in os.listdir(root)]\n",
        "\n",
        "        # if train:\n",
        "        #     self._files = self._files[:-600]\n",
        "        # else:\n",
        "        #     self._files = self._files[-600:]\n",
        "\n",
        "        self._cum_size = None\n",
        "        self._buffer = None\n",
        "        self._buffer_fnames = None\n",
        "        self._buffer_index = 0\n",
        "        self._buffer_size = buffer_size\n",
        "\n",
        "    def load_next_buffer(self):\n",
        "        \"\"\" Loads next buffer \"\"\"\n",
        "        self._buffer_fnames = self._files[self._buffer_index:self._buffer_index + self._buffer_size]\n",
        "        self._buffer_index += self._buffer_size\n",
        "        self._buffer_index = self._buffer_index % len(self._files)\n",
        "        self._buffer = []\n",
        "        self._cum_size = [0]\n",
        "\n",
        "        # progress bar\n",
        "        pbar = tqdm(total=len(self._buffer_fnames),\n",
        "                    bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} {postfix}')\n",
        "        pbar.set_description(\"Loading file buffer ...\")\n",
        "\n",
        "        for f in self._buffer_fnames:\n",
        "            with np.load(f) as data:\n",
        "                self._buffer += [{k: np.copy(v) for k, v in data.items()}]\n",
        "                self._cum_size += [self._cum_size[-1] +\n",
        "                                   self._data_per_sequence(data['reward'].shape[0])]\n",
        "            pbar.update(1)\n",
        "        pbar.close()\n",
        "\n",
        "    def __len__(self):\n",
        "        # to have a full sequence, you need self.seq_len + 1 elements, as\n",
        "        # you must produce both an seq_len obs and seq_len next_obs sequences\n",
        "        if not self._cum_size:\n",
        "            self.load_next_buffer()\n",
        "        return self._cum_size[-1]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # binary search through cum_size\n",
        "        file_index = bisect(self._cum_size, i) - 1\n",
        "        seq_index = i - self._cum_size[file_index]\n",
        "        data = self._buffer[file_index]\n",
        "        return self._get_data(data, seq_index)\n",
        "\n",
        "    def _get_data(self, data, seq_index):\n",
        "        pass\n",
        "\n",
        "    def _data_per_sequence(self, data_length):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RolloutSequenceDataset(_RolloutDataset): # pylint: disable=too-few-public-methods\n",
        "    \"\"\" Encapsulates rollouts.\n",
        "    Rollouts should be stored in subdirs of the root directory, in the form of npz files,\n",
        "    each containing a dictionary with the keys:\n",
        "        - observations: (rollout_len, *obs_shape)\n",
        "        - actions: (rollout_len, action_size)\n",
        "        - rewards: (rollout_len,)\n",
        "        - terminals: (rollout_len,), boolean\n",
        "     As the dataset is too big to be entirely stored in rams, only chunks of it\n",
        "     are stored, consisting of a constant number of files (determined by the\n",
        "     buffer_size parameter).  Once built, buffers must be loaded with the\n",
        "     load_next_buffer method.\n",
        "    Data are then provided in the form of tuples (obs, action, reward, terminal, next_obs):\n",
        "    - obs: (seq_len, *obs_shape)\n",
        "    - actions: (seq_len, action_size)\n",
        "    - reward: (seq_len,)\n",
        "    - terminal: (seq_len,) boolean\n",
        "    - next_obs: (seq_len, *obs_shape)\n",
        "    NOTE: seq_len < rollout_len in moste use cases\n",
        "    :args root: root directory of data sequences\n",
        "    :args seq_len: number of timesteps extracted from each rollout\n",
        "    :args transform: transformation of the observations\n",
        "    :args train: if True, train data, else test\n",
        "    \"\"\"\n",
        "    def __init__(self, root, seq_len, transform, buffer_size=200, train=True): # pylint: disable=too-many-arguments\n",
        "        super().__init__(root, transform, buffer_size, train)\n",
        "        self._seq_len = seq_len\n",
        "\n",
        "    def _get_data(self, data, seq_index):\n",
        "        obs_data = data['obs'][seq_index:seq_index + self._seq_len + 1]\n",
        "        obs_data = self._transform(obs_data.astype(np.float32))\n",
        "        obs, next_obs = obs_data[:-1], obs_data[1:]\n",
        "        action = data['action'][seq_index+1:seq_index + self._seq_len + 1]\n",
        "        action = action.astype(np.float32)\n",
        "        reward, terminal = [data[key][seq_index+1:\n",
        "                                      seq_index + self._seq_len + 1].astype(np.float32)\n",
        "                            for key in ('reward', 'done')]\n",
        "        # data is given in the form\n",
        "        # (obs, action, reward, terminal, next_obs)\n",
        "        return obs, action, reward, terminal, next_obs\n",
        "\n",
        "    def _data_per_sequence(self, data_length):\n",
        "        return data_length - self._seq_len"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc_63x7CCXmt"
      },
      "source": [
        "path=f\"{BASE_PATH}/record/\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmYDRkeniY6A"
      },
      "source": [
        "LATENT_SIZE=32\n",
        "ACTION_SIZE=3\n",
        "HIDDEN_SIZE=256\n",
        "GAUSSIAN_SIZE=5\n",
        "SEQ_LEN=32\n",
        "BSIZE=16"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4DYO3RW8eh2",
        "outputId": "c7588717-0c83-4d36-d0c8-b732530e2cb5"
      },
      "source": [
        "mdrnn = MDRNN(LATENT_SIZE, ACTION_SIZE, HIDDEN_SIZE, GAUSSIAN_SIZE).to(device)\n",
        "optimizer = torch.optim.RMSprop(mdrnn.parameters(), lr=1e-3, alpha=.9)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5)\n",
        "earlystopping = EarlyStopping('min', patience=30)\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.Lambda(lambda x: np.transpose(x, (0, 3, 1, 2)) / 255)])\n",
        "train_loader = torch.utils.data.DataLoader(RolloutSequenceDataset(path + \"train\", SEQ_LEN, transform, buffer_size=30), batch_size=BSIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(RolloutSequenceDataset(path + \"test\", SEQ_LEN, transform, buffer_size=10), batch_size=BSIZE, shuffle=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Loading file buffer ...: 100%|██████████| 10/10 \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AsPbgAFAsCE"
      },
      "source": [
        "\"\"\"\n",
        "Save randomly initialized weights\n",
        "\"\"\"\n",
        "torch.save(mdrnn.state_dict(), \"weights/mrnn_random.pt\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTfwg9hhuurK"
      },
      "source": [
        "def get_latent_obs(obs, normalize=False):\n",
        "  latent_obs = torch.Tensor().to(device)\n",
        "  if normalize:\n",
        "    obs = normalize(obs)\n",
        "  for i in obs:\n",
        "    latent_obs = torch.cat((latent_obs, torch.unsqueeze(vae.get_z(i), 0)))\n",
        "  return latent_obs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BexinebsDd7"
      },
      "source": [
        "def data_pass(epoch, train, include_reward): # pylint: disable=too-many-locals\n",
        "    \"\"\" One pass through the data \"\"\"\n",
        "    if train:\n",
        "        mdrnn.train()\n",
        "        loader = train_loader\n",
        "    else:\n",
        "        mdrnn.eval()\n",
        "        loader = test_loader\n",
        "\n",
        "    loader.dataset.load_next_buffer()\n",
        "\n",
        "    cum_loss = 0\n",
        "    cum_gmm = 0\n",
        "    cum_bce = 0\n",
        "    cum_mse = 0\n",
        "\n",
        "    pbar = tqdm(total=len(loader.dataset), desc=\"Epoch {}\".format(epoch))\n",
        "    for i, data in enumerate(loader):\n",
        "        obs, action, reward, terminal, next_obs = [arr.to(device) for arr in data]\n",
        "\n",
        "        # transform obs\n",
        "        latent_obs, latent_next_obs = get_latent_obs(obs), get_latent_obs(next_obs)\n",
        "        \n",
        "        if train:\n",
        "            losses = get_loss(latent_obs, action, reward,\n",
        "                              terminal, latent_next_obs, mdrnn, include_reward)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            losses['loss'].backward()\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                losses = get_loss(latent_obs, action, reward,\n",
        "                                  terminal, latent_next_obs, mdrnn, include_reward)\n",
        "\n",
        "        cum_loss += losses['loss'].item()\n",
        "        cum_gmm += losses['gmm'].item()\n",
        "        cum_bce += losses['bce'].item()\n",
        "        cum_mse += losses['mse'].item() if hasattr(losses['mse'], 'item') else \\\n",
        "            losses['mse']\n",
        "\n",
        "        pbar.set_postfix_str(\"loss={loss:10.6f} bce={bce:10.6f} \"\n",
        "                             \"gmm={gmm:10.6f} mse={mse:10.6f}\".format(\n",
        "                                 loss=cum_loss / (i + 1), bce=cum_bce / (i + 1),\n",
        "                                 gmm=cum_gmm / LATENT_SIZE / (i + 1), mse=cum_mse / (i + 1)))\n",
        "        pbar.update(BSIZE)\n",
        "    pbar.close()\n",
        "    print(f\"LOSS: {cum_loss * BSIZE / len(loader.dataset)}\")\n",
        "    return cum_loss * BSIZE / len(loader.dataset)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsvXMFog650h"
      },
      "source": [
        "rnn_dir = \"rnn_norm\"\n",
        "if not os.path.exists(rnn_dir):\n",
        "  os.mkdir(rnn_dir)\n",
        "rnn_file = join(rnn_dir, 'best.tar')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYuU-X7y9-KU"
      },
      "source": [
        "def save_checkpoint(state, is_best, filename, best_filename):\n",
        "    \"\"\" Save state in filename. Also save in best_filename if is_best. \"\"\"\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        torch.save(state, best_filename)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0akfA0x25G6B",
        "outputId": "94eeb6aa-b444-41f0-8af5-6584d122bb8c"
      },
      "source": [
        "train = partial(data_pass, train=True, include_reward=False)\n",
        "test = partial(data_pass, train=False, include_reward=False)\n",
        "\n",
        "cur_best = None\n",
        "epochs = 30\n",
        "\n",
        "for e in range(epochs):\n",
        "    train(e)\n",
        "    test_loss = test(e)\n",
        "    scheduler.step(test_loss)\n",
        "    earlystopping.step(test_loss)\n",
        "\n",
        "    is_best = not cur_best or test_loss < cur_best\n",
        "    if is_best:\n",
        "        cur_best = test_loss\n",
        "    checkpoint_fname = join(rnn_dir, 'checkpoint.tar')\n",
        "    save_checkpoint({\n",
        "        \"state_dict\": mdrnn.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict(),\n",
        "        'earlystopping': earlystopping.state_dict(),\n",
        "        \"precision\": test_loss,\n",
        "        \"epoch\": e}, is_best, checkpoint_fname,\n",
        "                    rnn_file)\n",
        "\n",
        "    if earlystopping.stop:\n",
        "        print(\"End of Training because of early stopping at epoch {}\".format(e))\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 0: 100%|██████████| 26256/26256 [02:17<00:00, 191.63it/s, loss=  0.963538 bce=  0.011475 gmm=  0.993290 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9635382298287061\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 0: 6880it [00:32, 211.04it/s, loss=  0.939101 bce=  0.000195 gmm=  0.968442 mse=  0.000000]\n",
            "Loading file buffer ...:   0%|          | 0/20 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9403310105922423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 20/20 \n",
            "Epoch 1: 15536it [01:19, 195.83it/s, loss=  0.925009 bce=  0.000082 gmm=  0.953913 mse=  0.000000]                           \n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9253067586190318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 1: 8944it [00:42, 208.57it/s, loss=  0.954473 bce=  0.000018 gmm=  0.984299 mse=  0.000000]                          \n",
            "Loading file buffer ...:  13%|█▎        | 4/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.954792876222792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 2: 22976it [01:57, 195.98it/s, loss=  0.899866 bce=  0.000123 gmm=  0.927983 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.900218746329639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 2: 6880it [00:33, 207.33it/s, loss=  0.923836 bce=  0.000196 gmm=  0.952700 mse=  0.000000]\n",
            "Loading file buffer ...:  13%|█▎        | 4/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9250462967449705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 3: 25680it [02:12, 193.76it/s, loss=  0.904959 bce=  0.000056 gmm=  0.933237 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9053113789887199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 3: 8944it [00:43, 204.70it/s, loss=  0.937313 bce=  0.000026 gmm=  0.966603 mse=  0.000000]                          \n",
            "Loading file buffer ...:  40%|████      | 4/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9376275494866371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 4: 8080it [00:41, 195.05it/s, loss=  0.904902 bce=  0.000055 gmm=  0.933178 mse=  0.000000]                          \n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9054622811946338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 4: 6880it [00:33, 207.28it/s, loss=  0.950718 bce=  0.000194 gmm=  0.980421 mse=  0.000000]\n",
            "Loading file buffer ...:  10%|█         | 3/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9519628583907803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 5: 24800it [02:07, 193.79it/s, loss=  0.870848 bce=  0.000089 gmm=  0.898060 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8709537707091618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 5: 8944it [00:43, 206.00it/s, loss=  0.924817 bce=  0.000034 gmm=  0.953716 mse=  0.000000]                          \n",
            "Loading file buffer ...:  10%|█         | 3/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9251269531548657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 6: 25216it [02:09, 194.45it/s, loss=  0.905691 bce=  0.000054 gmm=  0.933992 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9058705675980709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 6: 6880it [00:33, 207.40it/s, loss=  0.928807 bce=  0.000218 gmm=  0.957825 mse=  0.000000]\n",
            "Loading file buffer ...:  13%|█▎        | 4/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9300232791359326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 7: 22928it [01:57, 195.52it/s, loss=  0.894739 bce=  0.000124 gmm=  0.922696 mse=  0.000000]                           \n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8952076261133856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 7: 8944it [00:42, 209.20it/s, loss=  0.922920 bce=  0.000041 gmm=  0.951760 mse=  0.000000]                          \n",
            "Loading file buffer ...:  10%|█         | 3/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9232296889799712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 8: 100%|██████████| 26256/26256 [02:13<00:00, 197.29it/s, loss=  0.878279 bce=  0.000068 gmm=  0.905723 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8782790850968276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 8: 6880it [00:32, 208.73it/s, loss=  0.915731 bce=  0.000232 gmm=  0.944341 mse=  0.000000]\n",
            "Loading file buffer ...:   0%|          | 0/20 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9169307406717921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 20/20 \n",
            "Epoch 9: 15536it [01:22, 187.93it/s, loss=  0.891946 bce=  0.000081 gmm=  0.919817 mse=  0.000000]\n",
            "Loading file buffer ...:  20%|██        | 2/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8922335404436645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 9: 8944it [00:43, 204.64it/s, loss=  0.943099 bce=  0.000031 gmm=  0.972570 mse=  0.000000]                          \n",
            "Loading file buffer ...:  13%|█▎        | 4/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.943415421738799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 10: 22976it [01:58, 193.39it/s, loss=  0.871427 bce=  0.000136 gmm=  0.898655 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8717682368765618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 10: 6880it [00:33, 207.79it/s, loss=  0.915700 bce=  0.000232 gmm=  0.944308 mse=  0.000000]\n",
            "Loading file buffer ...:  13%|█▎        | 4/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9168992996771008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 11: 25680it [02:11, 195.81it/s, loss=  0.886595 bce=  0.000057 gmm=  0.914299 mse=  0.000000]                           \n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.88694009899768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 11: 8944it [00:42, 208.58it/s, loss=  0.934169 bce=  0.000033 gmm=  0.963361 mse=  0.000000]                          \n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9344823370309447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 12: 8080it [00:41, 193.52it/s, loss=  0.885796 bce=  0.000062 gmm=  0.913475 mse=  0.000000]                          \n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8863440319332914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 12: 6880it [00:33, 205.66it/s, loss=  0.939818 bce=  0.000204 gmm=  0.969181 mse=  0.000000]\n",
            "Loading file buffer ...:  10%|█         | 3/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9410486858391793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 13: 24800it [02:07, 194.16it/s, loss=  0.852574 bce=  0.000101 gmm=  0.879214 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8526776380662394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 13: 8944it [00:43, 207.29it/s, loss=  0.926979 bce=  0.000032 gmm=  0.955946 mse=  0.000000]                          \n",
            "Loading file buffer ...:  10%|█         | 3/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9272896524857467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 14: 25216it [02:09, 195.07it/s, loss=  0.894796 bce=  0.000049 gmm=  0.922757 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8949737469768217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 14: 6880it [00:32, 209.04it/s, loss=  0.928587 bce=  0.000218 gmm=  0.957598 mse=  0.000000]\n",
            "Loading file buffer ...:  13%|█▎        | 4/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9298029397013162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 15: 22928it [01:57, 195.26it/s, loss=  0.880959 bce=  0.000147 gmm=  0.908484 mse=  0.000000]                           \n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8814198664084095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 15: 8944it [00:42, 208.61it/s, loss=  0.924790 bce=  0.000029 gmm=  0.953689 mse=  0.000000]                          \n",
            "Loading file buffer ...:  10%|█         | 3/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9251007433772793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 16: 100%|██████████| 26256/26256 [02:14<00:00, 194.80it/s, loss=  0.862875 bce=  0.000066 gmm=  0.889838 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.862874841631948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 16: 6880it [00:33, 208.31it/s, loss=  0.920380 bce=  0.000231 gmm=  0.949135 mse=  0.000000]\n",
            "Loading file buffer ...:  20%|██        | 4/20 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9215860530601772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 20/20 \n",
            "Epoch 17: 15536it [01:24, 184.19it/s, loss=  0.879472 bce=  0.000087 gmm=  0.906953 mse=  0.000000]                           \n",
            "Loading file buffer ...:  20%|██        | 2/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8797555592122875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 17: 8944it [00:46, 193.52it/s, loss=  0.938244 bce=  0.000027 gmm=  0.967563 mse=  0.000000]\n",
            "Loading file buffer ...:  13%|█▎        | 4/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9385585040404031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 18: 22976it [01:59, 192.22it/s, loss=  0.857508 bce=  0.000139 gmm=  0.884301 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8578440747626663\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 18: 6880it [00:33, 204.06it/s, loss=  0.916966 bce=  0.000218 gmm=  0.945614 mse=  0.000000]\n",
            "Loading file buffer ...:  13%|█▎        | 4/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9181672150244482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 19: 25680it [02:12, 193.23it/s, loss=  0.876407 bce=  0.000062 gmm=  0.903793 mse=  0.000000]                           \n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8767482568468155\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 19: 8944it [00:42, 208.43it/s, loss=  0.933436 bce=  0.000029 gmm=  0.962605 mse=  0.000000]                          \n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9337494232259652\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 20: 8080it [00:41, 192.46it/s, loss=  0.874716 bce=  0.000063 gmm=  0.902049 mse=  0.000000]                          \n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8752579406171391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 20: 6880it [00:33, 203.84it/s, loss=  0.935888 bce=  0.000207 gmm=  0.965128 mse=  0.000000]\n",
            "Loading file buffer ...:  10%|█         | 3/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9371134550216468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 21: 24800it [02:07, 194.33it/s, loss=  0.838431 bce=  0.000100 gmm=  0.864629 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8385328905964232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 21: 8944it [00:43, 207.33it/s, loss=  0.931804 bce=  0.000031 gmm=  0.960922 mse=  0.000000]                          \n",
            "Loading file buffer ...:  10%|█         | 3/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9321164134471105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 22: 25216it [02:08, 195.52it/s, loss=  0.884187 bce=  0.000051 gmm=  0.911816 mse=  0.000000]\n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8843623279300535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 22: 6880it [00:33, 207.13it/s, loss=  0.927184 bce=  0.000212 gmm=  0.956152 mse=  0.000000]\n",
            "Loading file buffer ...:  13%|█▎        | 4/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9283984644654848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 23: 22928it [01:57, 194.55it/s, loss=  0.875294 bce=  0.000139 gmm=  0.902642 mse=  0.000000]                           \n",
            "Loading file buffer ...:  30%|███       | 3/10 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.8757522010453648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 10/10 \n",
            "Epoch 23: 8944it [00:43, 207.93it/s, loss=  0.926389 bce=  0.000030 gmm=  0.955337 mse=  0.000000]                          \n",
            "Loading file buffer ...:  10%|█         | 3/30 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS: 0.9266995864217946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading file buffer ...: 100%|██████████| 30/30 \n",
            "Epoch 24:   3%|▎         | 688/26256 [00:03<02:11, 194.48it/s, loss=  0.864929 bce=  0.000000 gmm=  0.891958 mse=  0.000000]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN0qSui9inrU"
      },
      "source": [
        "import tqdm\n",
        "def train(model, device, optimizer, train_loader, epoch, log_interval):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "      obs, action, reward, terminal, next_obs = [arr.to(device) for arr in data]\n",
        "      latent_obs, next_latent_obs = get_latent_obs(obs), get_latent_obs(next_obs)\n",
        "      loss = total_loss(latent_obs, action, reward, terminal, next_latent_obs, model)\n",
        "      losses.append(loss.item())\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if batch_idx % log_interval == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            epoch, batch_idx * len(obs), len(train_loader.dataset),\n",
        "            100. * batch_idx / len(train_loader), loss.item()))\n",
        "    return np.mean(losses)\n",
        "\n",
        "def test(model, device, optimizer, test_loader, epoch, log_interval):\n",
        "  model.eval()\n",
        "  losses = []\n",
        "  for batch_idx, data in enumerate(test_loader):\n",
        "    obs, action, reward, terminal, next_obs = [arr.to(device) for arr in data]\n",
        "    latent_obs, next_latent_obs = get_latent_obs(obs), get_latent_obs(next_obs)\n",
        "    loss = total_loss(latent_obs, action, reward, terminal, next_latent_obs, model)\n",
        "    losses.append(loss.item())\n",
        "    if batch_idx % log_interval == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            epoch, batch_idx * len(obs), len(test_loader.dataset),\n",
        "            100. * batch_idx / len(test_loader), loss.item()))\n",
        "  return np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH75Dyq-l4kO",
        "outputId": "33710923-7283-45da-8db3-d6dc21a696c3"
      },
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  train_loss = train(mdrnn, device, optimizer, mdrnn_train_loader, epoch, 20)\n",
        "  test_loss = test(mdrnn, device, optimizer, mdrnn_test_loader, epoch, 20)\n",
        "  print(f\"TRAIN LOSS: {train_loss}\")\n",
        "  print(f\"TEST LOSS: {test_loss}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/22916 (0%)]\tLoss: 1.360915\n",
            "Train Epoch: 0 [5120/22916 (22%)]\tLoss: 1.206958\n",
            "Train Epoch: 0 [10240/22916 (44%)]\tLoss: 1.117106\n",
            "Train Epoch: 0 [15360/22916 (67%)]\tLoss: 1.051065\n",
            "Train Epoch: 0 [20480/22916 (89%)]\tLoss: 1.045184\n",
            "Train Epoch: 0 [0/15812 (0%)]\tLoss: 1.025531\n",
            "Train Epoch: 0 [5120/15812 (32%)]\tLoss: 1.016624\n",
            "Train Epoch: 0 [10240/15812 (65%)]\tLoss: 1.014082\n",
            "Train Epoch: 0 [15360/15812 (97%)]\tLoss: 1.016561\n",
            "TRAIN LOSS: 1.1392824874983893\n",
            "TEST LOSS: 1.019655583366271\n",
            "Train Epoch: 1 [0/22916 (0%)]\tLoss: 1.010397\n",
            "Train Epoch: 1 [5120/22916 (22%)]\tLoss: 0.999077\n",
            "Train Epoch: 1 [10240/22916 (44%)]\tLoss: 0.988392\n",
            "Train Epoch: 1 [15360/22916 (67%)]\tLoss: 0.992204\n",
            "Train Epoch: 1 [20480/22916 (89%)]\tLoss: 0.973187\n",
            "Train Epoch: 1 [0/15812 (0%)]\tLoss: 0.983034\n",
            "Train Epoch: 1 [5120/15812 (32%)]\tLoss: 0.986771\n",
            "Train Epoch: 1 [10240/15812 (65%)]\tLoss: 0.993764\n",
            "Train Epoch: 1 [15360/15812 (97%)]\tLoss: 0.978581\n",
            "TRAIN LOSS: 1.0006110999319289\n",
            "TEST LOSS: 0.9898386357292053\n",
            "Train Epoch: 2 [0/22916 (0%)]\tLoss: 0.990330\n",
            "Train Epoch: 2 [5120/22916 (22%)]\tLoss: 1.010755\n",
            "Train Epoch: 2 [10240/22916 (44%)]\tLoss: 0.957127\n",
            "Train Epoch: 2 [15360/22916 (67%)]\tLoss: 0.956107\n",
            "Train Epoch: 2 [20480/22916 (89%)]\tLoss: 0.963499\n",
            "Train Epoch: 2 [0/15812 (0%)]\tLoss: 0.962431\n",
            "Train Epoch: 2 [5120/15812 (32%)]\tLoss: 0.968145\n",
            "Train Epoch: 2 [10240/15812 (65%)]\tLoss: 0.968529\n",
            "Train Epoch: 2 [15360/15812 (97%)]\tLoss: 0.956059\n",
            "TRAIN LOSS: 0.9692186190022363\n",
            "TEST LOSS: 0.9703782296949818\n",
            "Train Epoch: 3 [0/22916 (0%)]\tLoss: 0.961010\n",
            "Train Epoch: 3 [5120/22916 (22%)]\tLoss: 0.957249\n",
            "Train Epoch: 3 [10240/22916 (44%)]\tLoss: 0.952339\n",
            "Train Epoch: 3 [15360/22916 (67%)]\tLoss: 1.033545\n",
            "Train Epoch: 3 [20480/22916 (89%)]\tLoss: 0.995725\n",
            "Train Epoch: 3 [0/15812 (0%)]\tLoss: 0.940203\n",
            "Train Epoch: 3 [5120/15812 (32%)]\tLoss: 0.955960\n",
            "Train Epoch: 3 [10240/15812 (65%)]\tLoss: 0.945550\n",
            "Train Epoch: 3 [15360/15812 (97%)]\tLoss: 0.987510\n",
            "TRAIN LOSS: 0.9544592718283336\n",
            "TEST LOSS: 0.9553597011873799\n",
            "Train Epoch: 4 [0/22916 (0%)]\tLoss: 0.942539\n",
            "Train Epoch: 4 [5120/22916 (22%)]\tLoss: 0.945207\n",
            "Train Epoch: 4 [10240/22916 (44%)]\tLoss: 0.989265\n",
            "Train Epoch: 4 [15360/22916 (67%)]\tLoss: 0.932143\n",
            "Train Epoch: 4 [20480/22916 (89%)]\tLoss: 0.943552\n",
            "Train Epoch: 4 [0/15812 (0%)]\tLoss: 0.962131\n",
            "Train Epoch: 4 [5120/15812 (32%)]\tLoss: 0.948899\n",
            "Train Epoch: 4 [10240/15812 (65%)]\tLoss: 0.937847\n",
            "Train Epoch: 4 [15360/15812 (97%)]\tLoss: 0.938806\n",
            "TRAIN LOSS: 0.9450370649496714\n",
            "TEST LOSS: 0.9491371800822597\n",
            "Train Epoch: 5 [0/22916 (0%)]\tLoss: 0.956105\n",
            "Train Epoch: 5 [5120/22916 (22%)]\tLoss: 0.939662\n",
            "Train Epoch: 5 [10240/22916 (44%)]\tLoss: 0.922652\n",
            "Train Epoch: 5 [15360/22916 (67%)]\tLoss: 0.975955\n",
            "Train Epoch: 5 [20480/22916 (89%)]\tLoss: 0.927625\n",
            "Train Epoch: 5 [0/15812 (0%)]\tLoss: 0.941971\n",
            "Train Epoch: 5 [5120/15812 (32%)]\tLoss: 0.934683\n",
            "Train Epoch: 5 [10240/15812 (65%)]\tLoss: 0.945847\n",
            "Train Epoch: 5 [15360/15812 (97%)]\tLoss: 0.952558\n",
            "TRAIN LOSS: 0.9379956086476644\n",
            "TEST LOSS: 0.9511542935525218\n",
            "Train Epoch: 6 [0/22916 (0%)]\tLoss: 0.937247\n",
            "Train Epoch: 6 [5120/22916 (22%)]\tLoss: 0.971730\n",
            "Train Epoch: 6 [10240/22916 (44%)]\tLoss: 0.927799\n",
            "Train Epoch: 6 [15360/22916 (67%)]\tLoss: 0.935930\n",
            "Train Epoch: 6 [20480/22916 (89%)]\tLoss: 0.935627\n",
            "Train Epoch: 6 [0/15812 (0%)]\tLoss: 0.989573\n",
            "Train Epoch: 6 [5120/15812 (32%)]\tLoss: 0.936847\n",
            "Train Epoch: 6 [10240/15812 (65%)]\tLoss: 0.964211\n",
            "Train Epoch: 6 [15360/15812 (97%)]\tLoss: 0.937299\n",
            "TRAIN LOSS: 0.9328989446163177\n",
            "TEST LOSS: 0.9492613692437449\n",
            "Train Epoch: 7 [0/22916 (0%)]\tLoss: 0.914235\n",
            "Train Epoch: 7 [5120/22916 (22%)]\tLoss: 0.932110\n",
            "Train Epoch: 7 [10240/22916 (44%)]\tLoss: 0.921229\n",
            "Train Epoch: 7 [15360/22916 (67%)]\tLoss: 0.925937\n",
            "Train Epoch: 7 [20480/22916 (89%)]\tLoss: 0.918642\n",
            "Train Epoch: 7 [0/15812 (0%)]\tLoss: 0.947853\n",
            "Train Epoch: 7 [5120/15812 (32%)]\tLoss: 0.950258\n",
            "Train Epoch: 7 [10240/15812 (65%)]\tLoss: 0.948119\n",
            "Train Epoch: 7 [15360/15812 (97%)]\tLoss: 0.941021\n",
            "TRAIN LOSS: 0.9285666048526764\n",
            "TEST LOSS: 0.951151495018313\n",
            "Train Epoch: 8 [0/22916 (0%)]\tLoss: 0.959490\n",
            "Train Epoch: 8 [5120/22916 (22%)]\tLoss: 0.919506\n",
            "Train Epoch: 8 [10240/22916 (44%)]\tLoss: 0.919385\n",
            "Train Epoch: 8 [15360/22916 (67%)]\tLoss: 0.919590\n",
            "Train Epoch: 8 [20480/22916 (89%)]\tLoss: 0.917182\n",
            "Train Epoch: 8 [0/15812 (0%)]\tLoss: 0.950768\n",
            "Train Epoch: 8 [5120/15812 (32%)]\tLoss: 0.941772\n",
            "Train Epoch: 8 [10240/15812 (65%)]\tLoss: 0.946819\n",
            "Train Epoch: 8 [15360/15812 (97%)]\tLoss: 0.985882\n",
            "TRAIN LOSS: 0.9244079172611237\n",
            "TEST LOSS: 0.9505983321897445\n",
            "Train Epoch: 9 [0/22916 (0%)]\tLoss: 0.957128\n",
            "Train Epoch: 9 [5120/22916 (22%)]\tLoss: 0.920459\n",
            "Train Epoch: 9 [10240/22916 (44%)]\tLoss: 0.916500\n",
            "Train Epoch: 9 [15360/22916 (67%)]\tLoss: 0.913970\n",
            "Train Epoch: 9 [20480/22916 (89%)]\tLoss: 0.921688\n",
            "Train Epoch: 9 [0/15812 (0%)]\tLoss: 0.973051\n",
            "Train Epoch: 9 [5120/15812 (32%)]\tLoss: 0.941954\n",
            "Train Epoch: 9 [10240/15812 (65%)]\tLoss: 0.944592\n",
            "Train Epoch: 9 [15360/15812 (97%)]\tLoss: 0.941553\n",
            "TRAIN LOSS: 0.9212622119320764\n",
            "TEST LOSS: 0.9497643036227073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se4iZArHEFHm"
      },
      "source": [
        "torch.save(mdrnn.state_dict(), BASE_PATH + \"weights/mdrnn.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}